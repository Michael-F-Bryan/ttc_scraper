{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "from pprint import pprint\n",
    "import os\n",
    "import errno\n",
    "from collections import namedtuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, wait\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n",
    "def humansize(nbytes, decimals=2):\n",
    "    \"\"\"\n",
    "    Convert a number of bytes into it's human readable string using SI \n",
    "    suffixes.\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    1 KB = 1024 bytes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nbytes: int\n",
    "        The total number of bytes\n",
    "    decimals: int\n",
    "        The number of decimal places to round to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        The human readable size.\n",
    "\n",
    "    \"\"\"\n",
    "    if nbytes == 0: return '0 B'\n",
    "    i = 0\n",
    "    while nbytes >= 1024 and i < len(_suffixes)-1:\n",
    "        nbytes /= 1024.\n",
    "        i += 1\n",
    "    f = ('{}'.format(round(nbytes, decimals)))\n",
    "    f = f.rstrip('0').rstrip('.')\n",
    "    return '%s %s' % (f, _suffixes[i])\n",
    "\n",
    "def mkdir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "        logger.debug('Made directory: {}'.format(path))\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LoginError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "class Browser:\n",
    "    base_url = 'http://sae.wsu.edu/ttc/'\n",
    "    \n",
    "    def __init__(self, username, password, save_folder=None, force=False, workers=15):\n",
    "        logger.info('Initialising')\n",
    "        \n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.save_folder = save_folder or os.path.abspath('./downloads')\n",
    "        self.force = force\n",
    "        self.workers = workers\n",
    "        \n",
    "        mkdir(self.save_folder)\n",
    "        \n",
    "        self.session = requests.session()\n",
    "        \n",
    "    def login(self):\n",
    "        \"\"\"Logs into the TTC forum using the provided credentials.\"\"\"\n",
    "        logger.info('Logging in')\n",
    "        \n",
    "        r = self.session.get(self.base_url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            \n",
    "        form = soup.find(class_='quick-login').parent\n",
    "        href = urljoin(self.base_url, form['action'])\n",
    "        \n",
    "        payload = {\n",
    "            'username': self.username,\n",
    "            'password': self.password,\n",
    "            'login': 'Login',\n",
    "        }\n",
    "        # Send the actual login POST request\n",
    "        self.session.post(href, data=payload)\n",
    "        \n",
    "        # Now double check that we logged in successfully\n",
    "        r = self.session.get(urljoin(self.base_url, 'index.php'))\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        forum_titles = [x.text for x in soup.find_all(class_='forumtitle')]\n",
    "        if 'All Users Must Register' in forum_titles:\n",
    "            logger.error('Login unsuccessful')\n",
    "            raise LoginError('Login unsuccessful')\n",
    "        else:\n",
    "            logger.info('Login successful')\n",
    "            \n",
    "    def testing_rounds(self):\n",
    "        \"\"\"\n",
    "        Get links to each of the testing rounds' individual forums.\n",
    "        \"\"\"\n",
    "        logger.info('Getting links to each round')\n",
    "        \n",
    "        r = self.session.get(self.base_url + 'index.php')\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        forum_titles = soup.find_all(class_='forumtitle')\n",
    "        for title in forum_titles:\n",
    "            if 'Tire Testing' == title.text:\n",
    "                testing_form = urljoin(self.base_url, title['href'])\n",
    "                break\n",
    "        else:\n",
    "            raise RuntimeError('Could not find the \"Tire Testing\" forum')\n",
    "            \n",
    "        r = self.session.get(testing_form)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        forum_titles = soup.find_all(class_='forumtitle')\n",
    "        \n",
    "        links = []\n",
    "        for title in forum_titles:\n",
    "            url = urljoin(self.base_url, title['href'])\n",
    "            links.extend(self.get_data_links(url))\n",
    "            \n",
    "        logger.info('{} links found'.format(len(links)))\n",
    "        for link in links:\n",
    "            logger.debug(link)\n",
    "        return links\n",
    "            \n",
    "            \n",
    "    def get_data_links(self, forum_url):\n",
    "        \"\"\"\n",
    "        From each testing round's forum, get each of the posts which\n",
    "        contain testing data.\n",
    "        \"\"\"\n",
    "        logger.debug('Getting posts for forum: {}'.format(forum_url))\n",
    "        \n",
    "        pattern = re.compile(r'Round (\\d+) Data$')\n",
    "        r = self.session.get(forum_url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        topic_titles = soup.find_all(class_='topictitle')\n",
    "        links = []\n",
    "        for title in topic_titles:\n",
    "            res = pattern.search(title.text)\n",
    "            if res is not None:\n",
    "                links.append(title)\n",
    "               \n",
    "        hrefs = [urljoin(self.base_url, x['href']) for x in links]\n",
    "        for href in hrefs:\n",
    "            logger.debug('Post found: {}'.format(href))\n",
    "        return hrefs\n",
    "    \n",
    "    def scrape_round(self, round_url):\n",
    "        \"\"\"\n",
    "        Given a testing round post's url, find all the downloadable files.\n",
    "        \"\"\"\n",
    "        DownloadLink = namedtuple('DownloadLink', ['round', 'filename', 'link'])\n",
    "        \n",
    "        r = self.session.get(round_url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        round_title = re.search(r'\\d+', soup.find(id='page-body').h2.text).group()\n",
    "        logger.info('Getting download links for round {}'.format(round_title))\n",
    "\n",
    "        download_links = soup.find_all(href=re.compile(r'download'))\n",
    "        links = []\n",
    "        for link in download_links:\n",
    "            temp = DownloadLink(round_title, \n",
    "                                link.text,\n",
    "                                urljoin(self.base_url, link['href']))\n",
    "            links.append(temp)\n",
    "            \n",
    "        for link in links:\n",
    "            logger.debug('Download found: {}'.format(link))\n",
    "        return links\n",
    "    \n",
    "    def download(self, download_link):\n",
    "        \"\"\"\n",
    "        Given a DownloadLink, create it's parent folder and download it.\n",
    "        \"\"\"\n",
    "        logger.info('Downloading {}'.format(download_link))\n",
    "        \n",
    "        download_folder = os.path.join(self.save_folder, \n",
    "                              'Round_{}'.format(download_link.round))\n",
    "        mkdir(download_folder)\n",
    "        filename = os.path.join(download_folder, download_link.filename)\n",
    "        \n",
    "        if os.path.exists(filename) and not self.force:\n",
    "            logger.info('File already exists: {}'.format(filename))\n",
    "            return 0\n",
    "        \n",
    "        # Download the entire file and hold it in memory until the\n",
    "        # download is complete. This prevents us from having any\n",
    "        # incomplete downloads cluttering the filesystem \n",
    "        r = self.session.get(download_link.link)\n",
    "        \n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        \n",
    "        logger.info('{} bytes downloaded for Round {}, {}'.format(\n",
    "                len(r.content),\n",
    "                download_link.round,\n",
    "                download_link.filename))\n",
    "        return len(r.content)\n",
    "    \n",
    "    def _start_sequential(self):\n",
    "        logger.inf('Starting in  mode')\n",
    "        \n",
    "        self.login()\n",
    "        round_links = b.testing_rounds()\n",
    "        \n",
    "        files = []\n",
    "        for round_link in round_links:\n",
    "            temp = self.scrape_round(round_link)\n",
    "            files.extend(temp)\n",
    "            \n",
    "        total_downloads = 0\n",
    "        for file in files:\n",
    "            size = self.download(file)\n",
    "            total_downloads += size\n",
    "            \n",
    "        return total_downloads\n",
    "        \n",
    "    def _start_concurrent(self):\n",
    "        logger.inf('Starting in concurrent mode')\n",
    "        \n",
    "        pool = ThreadPoolExecutor(max_workers=self.workers)\n",
    "        self.login()\n",
    "        round_links = b.testing_rounds()\n",
    "        \n",
    "        futures = []\n",
    "        for link in round_links:\n",
    "            fut = pool.submit(self.scrape_round, link)\n",
    "            futures.append(fut)\n",
    "            \n",
    "        download_links = []\n",
    "        for future in as_completed(futures):\n",
    "            download_links.extend(future.result())\n",
    "            \n",
    "        futures = []\n",
    "        for download_link in download_links:\n",
    "            fut = pool.submit(self.download, download_link)\n",
    "            futures.append(fut)\n",
    "            \n",
    "        total_bytes = 0\n",
    "        for future in as_completed(futures):\n",
    "            download_size = future.result()\n",
    "            total_bytes += download_size\n",
    "            print(download_size)\n",
    "            \n",
    "        return total_bytes\n",
    "\n",
    "    start = _start_concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "7817\n",
      "11393\n",
      "34756\n",
      "400787\n",
      "153501\n",
      "748907\n",
      "11649024\n"
     ]
    }
   ],
   "source": [
    "username = 'kyleaurisch'\n",
    "password = 'lancer12'\n",
    "\n",
    "b = Browser(username, password)\n",
    "b.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
